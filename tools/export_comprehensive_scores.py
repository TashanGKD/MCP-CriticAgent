#!/usr/bin/env python3
"""
å¯¼å‡ºMCPå·¥å…·ç»¼åˆè¯„åˆ†æ•°æ®åˆ°CSVæ–‡ä»¶
åŒ…å«æµ‹è¯•ç»“æœå’ŒGitHubè¯„ä¼°çš„å®Œæ•´æ•°æ®

éµå¾ªLinusåŸåˆ™ï¼šæ•°æ®å°±æ˜¯ä¸€åˆ‡ï¼Œå¥½çš„æ•°æ®ç»“æ„èƒœè¿‡èŠ±å“¨çš„ä»£ç 
"""

import os
import sys
import csv
from pathlib import Path
from datetime import datetime
from rich.console import Console
from rich.progress import track
from dotenv import load_dotenv

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from src.core.evaluator import calculate_comprehensive_score_from_tests

def main():
    # åŠ è½½ç¯å¢ƒå˜é‡
    load_dotenv()
    
    console = Console()
    
    # æ£€æŸ¥ç¯å¢ƒå˜é‡
    supabase_url = os.getenv('SUPABASE_URL')
    supabase_key = os.getenv('SUPABASE_SERVICE_ROLE_KEY')
    
    if not supabase_url or not supabase_key:
        console.print("[red]âŒ ç¼ºå°‘Supabaseæ•°æ®åº“é…ç½®[/red]")
        return
    
    console.print("[blue]ğŸ—„ï¸ å¼€å§‹å¯¼å‡ºMCPå·¥å…·ç»¼åˆè¯„åˆ†æ•°æ®...[/blue]")
    
    try:
        from supabase import create_client
        client = create_client(supabase_url, supabase_key)
        
        # æŸ¥è¯¢æ‰€æœ‰æœ‰è¯„åˆ†çš„ä¸åŒå·¥å…·
        result = client.table('mcp_test_results')\
            .select('tool_identifier, tool_name, final_score')\
            .not_.is_('final_score', 'null')\
            .execute()
        
        if not result.data:
            console.print("[red]âŒ æ•°æ®åº“ä¸­æ²¡æœ‰æ‰¾åˆ°æµ‹è¯•æ•°æ®[/red]")
            return
        
        # å»é‡è·å–å”¯ä¸€å·¥å…·
        tools = {}
        for record in result.data:
            identifier = record['tool_identifier']
            if identifier not in tools:
                tools[identifier] = record['tool_name']
        
        # åˆ›å»ºè¾“å‡ºæ–‡ä»¶
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_file = f"mcp_comprehensive_scores_{timestamp}.csv"
        
        console.print(f"[green]âœ… æ‰¾åˆ° {len(tools)} ä¸ªå·¥å…·ï¼Œæ­£åœ¨è®¡ç®—ç»¼åˆè¯„åˆ†...[/green]")
        
        # CSVåˆ—å®šä¹‰
        fieldnames = [
            'tool_name',
            'github_url',
            'test_success_rate',
            'test_count',
            'successful_tests',
            'github_evaluation_score',
            'sustainability_score',
            'popularity_score',
            'comprehensive_score',
            'calculation_method',
            'quality_level',
            'export_timestamp'
        ]
        
        exported_count = 0
        
        with open(output_file, 'w', newline='', encoding='utf-8') as csvfile:
            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
            writer.writeheader()
            
            for github_url in track(tools.keys(), description="è®¡ç®—è¯„åˆ†..."):
                tool_name = tools[github_url]
                
                # è®¡ç®—ç»¼åˆè¯„åˆ†
                result = calculate_comprehensive_score_from_tests(github_url)
                
                if result and result.get('test_count', 0) > 0:
                    # ç¡®å®šè´¨é‡çº§åˆ«
                    comprehensive_score = result.get('comprehensive_score', 0)
                    if comprehensive_score >= 80:
                        quality_level = "ä¼˜ç§€"
                    elif comprehensive_score >= 60:
                        quality_level = "è‰¯å¥½"
                    else:
                        quality_level = "éœ€æ”¹è¿›"
                    
                    # å†™å…¥CSV
                    row = {
                        'tool_name': tool_name,
                        'github_url': github_url,
                        'test_success_rate': result.get('success_rate'),
                        'test_count': result.get('test_count'),
                        'successful_tests': result.get('successful_tests'),
                        'github_evaluation_score': result.get('github_evaluation_score'),
                        'sustainability_score': result.get('sustainability_score'),
                        'popularity_score': result.get('popularity_score'),
                        'comprehensive_score': comprehensive_score,
                        'calculation_method': result.get('calculation_method'),
                        'quality_level': quality_level,
                        'export_timestamp': datetime.now().isoformat()
                    }
                    
                    writer.writerow(row)
                    exported_count += 1
                else:
                    console.print(f"[dim yellow]âš ï¸ è·³è¿‡æ— æµ‹è¯•æ•°æ®çš„å·¥å…·: {tool_name}[/dim yellow]")
        
        console.print(f"[green]âœ… æˆåŠŸå¯¼å‡º {exported_count} ä¸ªå·¥å…·çš„ç»¼åˆè¯„åˆ†æ•°æ®[/green]")
        console.print(f"[blue]ğŸ“„ è¾“å‡ºæ–‡ä»¶: {output_file}[/blue]")
        
        # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
        console.print(f"\n[bold]ğŸ“Š å¯¼å‡ºç»Ÿè®¡[/bold]")
        console.print(f"  æ€»å·¥å…·æ•°: {len(tools)}")
        console.print(f"  æœ‰æ•ˆæ•°æ®: {exported_count}")
        console.print(f"  æ•°æ®æ—¶é—´: {timestamp}")
        
        # æ˜¾ç¤ºæ–‡ä»¶å¤§å°
        file_size = os.path.getsize(output_file)
        console.print(f"  æ–‡ä»¶å¤§å°: {file_size:,} å­—èŠ‚")
        
        console.print(f"\n[dim]ğŸ’¡ ä½¿ç”¨Excelæˆ–å…¶ä»–å·¥å…·æ‰“å¼€ {output_file} è¿›è¡Œè¿›ä¸€æ­¥åˆ†æ[/dim]")
        
    except Exception as e:
        console.print(f"[red]âŒ å¯¼å‡ºå¤±è´¥: {e}[/red]")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()

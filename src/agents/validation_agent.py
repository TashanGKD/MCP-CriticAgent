#!/usr/bin/env python3
"""
æ™ºèƒ½éªŒè¯æ‰§è¡Œä»£ç†

åŸºäºAgentScopeå®ç°çš„æ™ºèƒ½æµ‹è¯•æ‰§è¡Œå’ŒéªŒè¯å™¨
è‡ªåŠ¨æ‰§è¡Œæµ‹è¯•ç”¨ä¾‹å¹¶åˆ†æç»“æœ

ä½œè€…: AI Assistant  
æ—¥æœŸ: 2025-08-15
"""

import os
import json
import time
import asyncio
from pathlib import Path
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass
from enum import Enum

try:
    import agentscope
    from agentscope.agents import ReActAgent
    from agentscope.message import Msg
    from dotenv import load_dotenv
except ImportError as e:
    print(f"âŒ AgentScopeå¯¼å…¥å¤±è´¥: {e}")
    print("è¯·ç¡®ä¿å·²å®‰è£… agentscope å’Œ python-dotenv")

from src.agents.test_agent import TestCase

class TestResultStatus(Enum):
    """æµ‹è¯•ç»“æœçŠ¶æ€"""
    PASS = "pass"
    FAIL = "fail" 
    ERROR = "error"
    SKIP = "skip"

@dataclass
class TestResult:
    """æµ‹è¯•ç»“æœæ•°æ®ç»“æ„"""
    test_case: TestCase
    status: TestResultStatus
    execution_time: float
    response: Optional[Dict[str, Any]] = None
    error_message: Optional[str] = None
    analysis: Optional[str] = None

class ValidationAgent:
    """æ™ºèƒ½éªŒè¯æ‰§è¡Œä»£ç†"""
    
    def __init__(self, model_config: Optional[Dict] = None):
        self.model_config = model_config or self._load_default_config()
        self.agent = None
        self._initialize_agent()
    
    def _load_default_config(self) -> Dict:
        """åŠ è½½é»˜è®¤æ¨¡å‹é…ç½®"""
        env_path = Path(__file__).parent.parent.parent / ".env"
        load_dotenv(env_path)
        
        return {
            "config_name": "validation_agent_config",
            "model_type": "openai_chat", 
            "model_name": os.getenv("OPENAI_MODEL", "qwen-plus"),
            "api_key": os.getenv("OPENAI_API_KEY"),
            "client_args": {
                "base_url": os.getenv("OPENAI_BASE_URL"),
                "timeout": 60  # å¢åŠ åˆ°60ç§’è¶…æ—¶
            },
            "generate_args": {
                "temperature": 0.3,  # è¾ƒä½æ¸©åº¦ä»¥è·å¾—æ›´ä¸€è‡´çš„åˆ†æ
                "max_tokens": 800   # å‡å°‘tokenæ•°é‡åŠ å¿«å“åº”
            }
        }
    
    def _initialize_agent(self):
        """åˆå§‹åŒ–AgentScopeä»£ç†"""
        try:
            # åˆå§‹åŒ–AgentScope  
            agentscope.init(
                model_configs=[self.model_config],
                project="MCP_Test_Validator",
                save_dir="./logs",
                save_log=True,
                save_api_invoke=True
            )
            
            # åˆ›å»ºéªŒè¯ä»£ç† - ä½¿ç”¨å¯ç”¨çš„ä»£ç†ç±»
            sys_prompt = self._get_validation_prompt()
            
            try:
                from agentscope.agents import DialogAgent
                self.agent = DialogAgent(
                    name="mcp_test_validator",
                    model_config_name=self.model_config["config_name"],
                    sys_prompt=sys_prompt
                )
            except TypeError:
                # å¤„ç†AgentScopeç‰ˆæœ¬å…¼å®¹æ€§é—®é¢˜ï¼Œç§»é™¤ä¸æ”¯æŒçš„å‚æ•°
                from agentscope.agents import DialogAgent
                self.agent = DialogAgent(
                    name="mcp_test_validator",
                    sys_prompt=sys_prompt
                )
            
            print("âœ… éªŒè¯æ‰§è¡Œä»£ç†åˆå§‹åŒ–æˆåŠŸ")
            
        except Exception as e:
            print(f"âŒ ä»£ç†åˆå§‹åŒ–å¤±è´¥: {e}")
            self.agent = None
    
    def _get_validation_prompt(self) -> str:
        """è·å–éªŒè¯ä»£ç†çš„ç³»ç»Ÿæç¤ºè¯"""
        return '''ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„MCP(Model Context Protocol)å·¥å…·æµ‹è¯•ç»“æœåˆ†æä¸“å®¶ã€‚

ä½ çš„ä»»åŠ¡æ˜¯ä»¥å®ç”¨ã€å®½æ¾çš„æ ‡å‡†åˆ†ææµ‹è¯•æ‰§è¡Œç»“æœï¼Œé‡ç‚¹å…³æ³¨å·¥å…·æ˜¯å¦èƒ½æ­£å¸¸å·¥ä½œï¼Œè€Œä¸æ˜¯å®Œç¾åŒ¹é…é¢„æœŸã€‚

## è¾“å…¥ä¿¡æ¯æ ¼å¼:
- æµ‹è¯•ç”¨ä¾‹åç§°: [name]
- æµ‹è¯•æè¿°: [description]  
- è°ƒç”¨å·¥å…·: [tool_name]
- è¾“å…¥å‚æ•°: [parameters]
- æœŸæœ›ç»“æœç±»å‹: [expected_type]
- æœŸæœ›ç»“æœå†…å®¹: [expected_result]
- å®é™…æ‰§è¡Œæ—¶é—´: [execution_time]
- å®é™…å“åº”: [actual_response]
- é”™è¯¯ä¿¡æ¯: [error_message]

## å®½æ¾çš„åˆ†æåŸåˆ™:
1. **åŸºæœ¬åŠŸèƒ½æ€§** - å·¥å…·æ˜¯å¦å“åº”å¹¶è¿”å›äº†ç»“æ„åŒ–æ•°æ®
2. **å†…å®¹ç›¸å…³æ€§** - è¿”å›å†…å®¹æ˜¯å¦ä¸è¾“å…¥å‚æ•°ç›¸å…³ï¼ˆä¸å¿…å®Œç¾åŒ¹é…ï¼‰
3. **åˆç†æ€§èƒ½** - å“åº”æ—¶é—´æ˜¯å¦åœ¨å¯æ¥å—èŒƒå›´å†…ï¼ˆ<30ç§’é€šå¸¸å¯æ¥å—ï¼‰
4. **ç¨³å®šæ€§** - å·¥å…·æ²¡æœ‰å´©æºƒæˆ–è¿”å›ä¹±ç 

## å®½æ¾åˆ¤æ–­æ ‡å‡†ï¼ˆæ›´å®¹æ˜“é€šè¿‡ï¼‰:
- **PASS**: å·¥å…·æ­£å¸¸å“åº”ï¼Œè¿”å›æœ‰æ„ä¹‰çš„æ•°æ®ï¼Œå†…å®¹åŸºæœ¬ç›¸å…³
  - å³ä½¿æ ¼å¼ä¸å®Œå…¨ç¬¦åˆé¢„æœŸä¹Ÿå¯ä»¥é€šè¿‡
  - å³ä½¿è¿”å›çš„å…·ä½“å†…å®¹ä¸æœŸæœ›æœ‰å·®å¼‚ï¼Œåªè¦ç›¸å…³å³å¯
  - å·¥å…·è¿”å›éƒ¨åˆ†ç»“æœæˆ–ç›¸ä¼¼ç»“æœä¹Ÿç®—æˆåŠŸ
  
- **FAIL**: åªæœ‰åœ¨ä»¥ä¸‹æƒ…å†µæ‰åˆ¤æ–­å¤±è´¥
  - å·¥å…·è¿”å›çš„å†…å®¹å®Œå…¨ä¸ç›¸å…³æˆ–æ— æ„ä¹‰
  - æ˜æ˜¾çš„åŠŸèƒ½æ€§é”™è¯¯ï¼ˆå¦‚æœç´¢"python"å´è¿”å›"java"ç›¸å…³å†…å®¹ï¼‰
  - è¿”å›ç©ºå†…å®¹ä½†åº”è¯¥æœ‰ç»“æœçš„æƒ…å†µ
  
- **ERROR**: ä»…åœ¨ä¸¥é‡æŠ€æœ¯é—®é¢˜æ—¶ä½¿ç”¨
  - å·¥å…·å®Œå…¨æ— æ³•å“åº”
  - è¿”å›ç³»ç»Ÿé”™è¯¯æˆ–å´©æºƒä¿¡æ¯
  - JSONæ ¼å¼ä¸¥é‡é”™è¯¯å¯¼è‡´æ— æ³•è§£æ

## ç‰¹æ®Šæƒ…å†µå¤„ç†:
- å¯¹äºexpected_type="error"çš„æµ‹è¯•ï¼Œåªè¦å·¥å…·æœ‰æ˜ç¡®æç¤ºï¼ˆä¸ç®¡æ˜¯é”™è¯¯è¿˜æ˜¯å‹å¥½æç¤ºï¼‰éƒ½å¯é€šè¿‡
- å¯¹äºæœç´¢ç±»å·¥å…·ï¼Œè¿”å›ç›¸è¿‘ç»“æœæ¯”è¿”å›é”™è¯¯æ›´å¥½
- å¯¹äºæ–‡æ¡£è·å–ï¼Œè¿”å›ä»»ä½•ç›¸å…³å†…å®¹éƒ½æ¯”æ— å†…å®¹å¥½
- æ€§èƒ½æµ‹è¯•ï¼šåªè¦<30ç§’éƒ½ç®—åˆç†

## è¾“å‡ºæ ¼å¼:
è¯·ä»¥JSONæ ¼å¼è¾“å‡ºåˆ†æç»“æœ:
```json
{
  "status": "pass|fail|error",
  "confidence": 0.0-1.0,
  "analysis": "è¯¦ç»†åˆ†æè¯´æ˜ï¼Œè§£é‡Šä¸ºä»€ä¹ˆé€šè¿‡æˆ–å¤±è´¥",
  "issues": ["ä»…åˆ—å‡ºä¸¥é‡é—®é¢˜ï¼Œä¸åŒ…æ‹¬æ ¼å¼æˆ–ç»†èŠ‚å·®å¼‚"],
  "recommendations": ["å®ç”¨çš„æ”¹è¿›å»ºè®®ï¼Œä¸è¿½æ±‚å®Œç¾"]
}
```

è¯·è®°ä½ï¼šæˆ‘ä»¬çš„ç›®æ ‡æ˜¯éªŒè¯å·¥å…·çš„åŸºæœ¬å¯ç”¨æ€§ï¼Œä¸æ˜¯è¿½æ±‚å®Œç¾çš„APIè¡Œä¸ºã€‚å®½æ¾ä½†å®ç”¨çš„æ ‡å‡†æ›´æœ‰ä»·å€¼ã€‚'''
    
    async def execute_test_suite(self, test_cases: List[TestCase], mcp_client) -> List[TestResult]:
        """æ‰§è¡Œæµ‹è¯•å¥—ä»¶"""
        results = []
        
        print(f"ğŸš€ å¼€å§‹æ‰§è¡Œ {len(test_cases)} ä¸ªæµ‹è¯•ç”¨ä¾‹")
        
        for i, test_case in enumerate(test_cases, 1):
            print(f"\n[{i}/{len(test_cases)}] æ‰§è¡Œæµ‹è¯•: {test_case.name}")
            
            try:
                result = await self._execute_single_test(test_case, mcp_client)
                results.append(result)
                
                # æ˜¾ç¤ºç®€è¦ç»“æœ
                status_icon = "âœ…" if result.status == TestResultStatus.PASS else "âŒ" if result.status == TestResultStatus.FAIL else "âš ï¸"
                print(f"{status_icon} {result.status.value.upper()} ({result.execution_time:.2f}s)")
                
            except Exception as e:
                print(f"âŒ æµ‹è¯•æ‰§è¡Œå¼‚å¸¸: {e}")
                error_result = TestResult(
                    test_case=test_case,
                    status=TestResultStatus.ERROR,
                    execution_time=0.0,
                    error_message=str(e),
                    analysis="æµ‹è¯•æ‰§è¡Œè¿‡ç¨‹ä¸­å‘ç”Ÿå¼‚å¸¸"
                )
                results.append(error_result)
        
        # ç”Ÿæˆæµ‹è¯•æŠ¥å‘Šæ‘˜è¦
        self._print_test_summary(results)
        
        return results
    
    async def _execute_single_test(self, test_case: TestCase, mcp_client) -> TestResult:
        """æ‰§è¡Œå•ä¸ªæµ‹è¯•ç”¨ä¾‹"""
        start_time = time.time()
        
        try:
            # æ‰§è¡ŒMCPå·¥å…·è°ƒç”¨
            if test_case.tool_name == "tools/list":
                # ç‰¹æ®Šå¤„ç†å·¥å…·åˆ—è¡¨è°ƒç”¨
                response = await mcp_client.list_tools()
            elif test_case.tool_name == "config_check":
                # ç‰¹æ®Šå¤„ç†é…ç½®æ£€æŸ¥
                response = {"status": "success", "message": "é…ç½®æ£€æŸ¥é€šè¿‡"}
            else:
                # æ‰§è¡Œæ™®é€šå·¥å…·è°ƒç”¨
                response = await mcp_client.call_tool(
                    test_case.tool_name,
                    test_case.parameters
                )
            
            execution_time = time.time() - start_time
            
            # ä½¿ç”¨AIä»£ç†åˆ†æç»“æœ
            analysis_result = await self._analyze_test_result(test_case, response, execution_time)
            
            # æ„å»ºæµ‹è¯•ç»“æœ
            result = TestResult(
                test_case=test_case,
                status=TestResultStatus(analysis_result.get("status", "error")),
                execution_time=execution_time,
                response=response,
                analysis=analysis_result.get("analysis", "")
            )
            
            return result
            
        except Exception as e:
            execution_time = time.time() - start_time
            
            return TestResult(
                test_case=test_case,
                status=TestResultStatus.ERROR,
                execution_time=execution_time,
                error_message=str(e),
                analysis=f"æµ‹è¯•æ‰§è¡Œå¤±è´¥: {str(e)}"
            )
    
    async def _analyze_test_result(self, test_case: TestCase, response: Dict[str, Any], execution_time: float) -> Dict[str, Any]:
        """ä½¿ç”¨AIä»£ç†åˆ†ææµ‹è¯•ç»“æœ"""
        try:
            if self.agent is None:
                print("âš ï¸ AIä»£ç†ä¸å¯ç”¨ï¼Œä½¿ç”¨åŸºç¡€è§„åˆ™åˆ†æ")
                return self._basic_result_analysis(test_case, response, execution_time)
            
            # æ„å»ºåˆ†ææç¤º
            analysis_prompt = f"""
è¯·åˆ†æä»¥ä¸‹MCPå·¥å…·æµ‹è¯•ç»“æœ:

æµ‹è¯•ç”¨ä¾‹åç§°: {test_case.name}
æµ‹è¯•æè¿°: {test_case.description}
è°ƒç”¨å·¥å…·: {test_case.tool_name}
è¾“å…¥å‚æ•°: {json.dumps(test_case.parameters, ensure_ascii=False)}
æœŸæœ›ç»“æœç±»å‹: {test_case.expected_type}
æœŸæœ›ç»“æœå†…å®¹: {test_case.expected_result or "æœªæŒ‡å®š"}
æ‰§è¡Œæ—¶é—´: {execution_time:.3f}ç§’

å®é™…å“åº”:
{json.dumps(response, indent=2, ensure_ascii=False)}

è¯·åˆ†æè¿™ä¸ªæµ‹è¯•æ˜¯å¦é€šè¿‡ï¼Œå¹¶æä¾›è¯¦ç»†åˆ†æã€‚
"""
            
            print(f"ğŸ¤– æ­£åœ¨è°ƒç”¨AIä»£ç†åˆ†ææµ‹è¯•ç»“æœ...")
            print("ğŸ“¡ å‘é€è¯·æ±‚åˆ°å¤§æ¨¡å‹API...")
            
            # è°ƒç”¨åˆ†æä»£ç† - çœŸå®çš„å¤§æ¨¡å‹è°ƒç”¨
            user_msg = Msg("user", analysis_prompt, role="user")
            agent_response = self.agent(user_msg)
            
            print(f"ğŸ¯ å¤§æ¨¡å‹åˆ†æå®Œæˆ")
            
            # è§£æä»£ç†å“åº”
            return self._parse_analysis_response(agent_response.content)
            
        except Exception as e:
            print(f"âš ï¸ AIåˆ†æå¤±è´¥ï¼Œä½¿ç”¨åŸºç¡€è§„åˆ™: {e}")
            return self._basic_result_analysis(test_case, response, execution_time)
    
    def _parse_analysis_response(self, response: str) -> Dict[str, Any]:
        """è§£æAIä»£ç†çš„åˆ†æå“åº”"""
        try:
            # å°è¯•ä»å“åº”ä¸­æå–JSON
            import re
            json_match = re.search(r'```json\s*(.*?)\s*```', response, re.DOTALL)
            if json_match:
                json_str = json_match.group(1)
                return json.loads(json_str)
            else:
                # å¦‚æœæ²¡æœ‰æ‰¾åˆ°JSONæ ¼å¼ï¼Œå°è¯•ç›´æ¥è§£æ
                return json.loads(response)
                
        except (json.JSONDecodeError, AttributeError):
            # è§£æå¤±è´¥ï¼Œè¿”å›åŸºç¡€åˆ†æ
            return {
                "status": "error",
                "confidence": 0.5,
                "analysis": "AIåˆ†æå“åº”è§£æå¤±è´¥",
                "issues": ["å“åº”æ ¼å¼ä¸æ­£ç¡®"],
                "recommendations": ["æ£€æŸ¥AIæ¨¡å‹é…ç½®"]
            }
    
    def _basic_result_analysis(self, test_case: TestCase, response: Dict[str, Any], execution_time: float) -> Dict[str, Any]:
        """åŸºç¡€è§„åˆ™åˆ†ææµ‹è¯•ç»“æœ"""
        try:
            # åŸºç¡€æˆåŠŸåˆ¤æ–­
            if response and not response.get("error"):
                status = "pass"
                analysis = "å·¥å…·è°ƒç”¨æˆåŠŸï¼Œè¿”å›äº†æœ‰æ•ˆå“åº”"
                issues = []
            else:
                status = "fail"
                analysis = "å·¥å…·è°ƒç”¨å¤±è´¥æˆ–è¿”å›é”™è¯¯"
                issues = ["å·¥å…·å“åº”åŒ…å«é”™è¯¯ä¿¡æ¯"]
            
            # æ€§èƒ½æ£€æŸ¥
            if execution_time > 10.0:
                issues.append(f"å“åº”æ—¶é—´è¿‡é•¿ ({execution_time:.2f}s)")
            
            return {
                "status": status,
                "confidence": 0.7,
                "analysis": analysis,
                "issues": issues,
                "recommendations": ["ä½¿ç”¨AIä»£ç†è¿›è¡Œè¯¦ç»†åˆ†æ"] if issues else []
            }
            
        except Exception:
            return {
                "status": "error",
                "confidence": 0.3,
                "analysis": "åŸºç¡€åˆ†æå¤±è´¥",
                "issues": ["æ— æ³•åˆ†ææµ‹è¯•ç»“æœ"],
                "recommendations": ["æ£€æŸ¥å“åº”æ•°æ®æ ¼å¼"]
            }
    
    def _print_test_summary(self, results: List[TestResult]):
        """æ‰“å°æµ‹è¯•æ‘˜è¦"""
        total = len(results)
        passed = len([r for r in results if r.status == TestResultStatus.PASS])
        failed = len([r for r in results if r.status == TestResultStatus.FAIL])
        errors = len([r for r in results if r.status == TestResultStatus.ERROR])
        
        print(f"\nğŸ“Š æµ‹è¯•æ‰§è¡Œæ‘˜è¦:")
        print(f"   æ€»è®¡: {total}")
        print(f"   é€šè¿‡: {passed} âœ…")
        print(f"   å¤±è´¥: {failed} âŒ")
        print(f"   é”™è¯¯: {errors} âš ï¸")
        print(f"   æˆåŠŸç‡: {(passed/total*100):.1f}%")
        
        # æ˜¾ç¤ºå¹³å‡æ‰§è¡Œæ—¶é—´
        avg_time = sum(r.execution_time for r in results) / total if total > 0 else 0
        print(f"   å¹³å‡æ‰§è¡Œæ—¶é—´: {avg_time:.2f}s")

# å…¨å±€éªŒè¯ä»£ç†å®ä¾‹
_validation_agent_instance = None

def get_validation_agent() -> ValidationAgent:
    """è·å–å…¨å±€éªŒè¯ä»£ç†å®ä¾‹"""
    global _validation_agent_instance
    if _validation_agent_instance is None:
        _validation_agent_instance = ValidationAgent()
    return _validation_agent_instance

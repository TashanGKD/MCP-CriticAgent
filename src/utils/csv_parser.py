#!/usr/bin/env python3
"""
CSVæ•°æ®è§£æå™¨

ä»data/mcp.csvè§£æMCPå·¥å…·ä¿¡æ¯ï¼Œæä¾›ç»“æ„åŒ–çš„æ•°æ®è®¿é—®æ¥å£

ä½œè€…: AI Assistant
æ—¥æœŸ: 2025-08-15
"""

import pandas as pd
from pathlib import Path
from typing import Dict, List, Optional, Any
import json
import re
from dataclasses import dataclass, field
from rich.console import Console

console = Console()

@dataclass
class MCPToolInfo:
    """MCPå·¥å…·ä¿¡æ¯æ•°æ®ç±»"""
    name: str
    url: str
    author: str
    github_url: str
    description: str
    deployment_method: str
    category: str = ""
    package_name: Optional[str] = None
    requires_api_key: bool = False
    install_command: Optional[str] = None
    run_command: Optional[str] = None
    api_requirements: List[str] = field(default_factory=list)
    final_score: Optional[int] = None
    sustainability_score: Optional[int] = None
    popularity_score: Optional[int] = None
    
    # LobeHubè¯„åˆ†ä¿¡æ¯
    lobehub_url: Optional[str] = None
    lobehub_evaluate: Optional[str] = None      # ä¼˜è´¨/è‰¯å¥½/æ¬ ä½³
    lobehub_score: Optional[float] = None       # å…·ä½“è¯„åˆ†æ•°å­—
    lobehub_star_count: Optional[int] = None    # GitHubæ˜Ÿæ ‡æ•°
    lobehub_fork_count: Optional[int] = None    # GitHubåˆ†æ”¯æ•°

class MCPDataParser:
    """MCPæ•°æ®è§£æå™¨"""
    
    def __init__(self, csv_path: str):
        self.csv_path = Path(csv_path)
        self.df = None
        self.tools_cache = {}
    
    def normalize_field_names(self, row: Dict[str, Any]) -> Dict[str, Any]:
        """
        å°†mcp.csvçš„å­—æ®µåæ ‡å‡†åŒ–ä¸ºæœŸæœ›çš„å­—æ®µå
        è¿™æ ·å¯ä»¥ç»Ÿä¸€å¤„ç†ä¸¤ç§CSVæ ¼å¼ï¼Œæ¶ˆé™¤ç‰¹æ®Šæƒ…å†µ
        """
        import json
        
        # mcp.csv -> expected field mapping
        field_mapping = {
            'extracted_deployment_methods': 'deployment_method', 
            'extracted_requires_api_key': 'requires_api_key',
            'extracted_use_cases': 'use_cases'
        }
        
        normalized = {}
        for key, value in row.items():
            # Use mapping if exists, otherwise keep original key
            normalized_key = field_mapping.get(key, key)
            normalized[normalized_key] = value
            
        # Extract install_command and run_command from extracted_mcp_config
        if 'extracted_mcp_config' in row and pd.notna(row['extracted_mcp_config']):
            try:
                config_str = str(row['extracted_mcp_config']).strip()
                if config_str:
                    config = json.loads(config_str)
                    if 'install_command' in config:
                        normalized['install_command'] = config['install_command']
                    if 'run_command' in config:
                        normalized['run_command'] = config['run_command']
            except (json.JSONDecodeError, Exception) as e:
                console.print(f"[yellow]âš ï¸ è§£æmcp_configå¤±è´¥: {e}[/yellow]")
        
        # Handle special cases for deployment_method 
        if 'deployment_method' in normalized and pd.notna(normalized['deployment_method']):
            # Extract the first deployment method if multiple exist
            deploy_val = str(normalized['deployment_method'])
            if 'npm' in deploy_val.lower() or 'npx' in deploy_val.lower():
                normalized['deployment_method'] = 'npx'
            elif 'pip' in deploy_val.lower():
                normalized['deployment_method'] = 'pip'
            else:
                normalized['deployment_method'] = 'npx'  # default
        else:
            normalized['deployment_method'] = 'npx'  # default for missing values
            
        # Handle API key requirements
        if 'requires_api_key' in normalized:
            api_key_val = str(normalized['requires_api_key']).lower()
            normalized['requires_api_key'] = api_key_val in ['true', '1', 'yes', 'required']
        else:
            normalized['requires_api_key'] = False
            
        return normalized
        
    def load_data(self) -> bool:
        """åŠ è½½CSVæ•°æ®"""
        try:
            if not self.csv_path.exists():
                console.print(f"[red]âŒ CSVæ–‡ä»¶ä¸å­˜åœ¨: {self.csv_path}[/red]")
                return False
            
            console.print(f"[blue]ğŸ“Š åŠ è½½MCPæ•°æ®: {self.csv_path}[/blue]")
            # ç›´æ¥ä½¿ç”¨pandasè¯»å–CSVï¼Œæ›´åŠ ç¨³å®šå¯é 
            self.df = pd.read_csv(self.csv_path, encoding='utf-8')
            console.print(f"[green]âœ… æˆåŠŸåŠ è½½ {len(self.df)} æ¡MCPå·¥å…·è®°å½•[/green]")
            return True
            
        except Exception as e:
            console.print(f"[red]âŒ åŠ è½½CSVæ•°æ®å¤±è´¥: {e}[/red]")
            return False
    
    def extract_package_name(self, install_command: str, run_command: str, deployment_method: str) -> Optional[str]:
        """ä»å‘½ä»¤ä¸­æå–åŒ…å"""
        if deployment_method not in ['npm', 'npx']:
            return None

        command = run_command if pd.notna(run_command) and run_command else install_command
        if pd.isna(command) or not command:
            return None

        # Regex to find package names, including scoped packages
        match = re.search(r'(?:npx -y |@)[^\s@/]+(?:/[^\s@]+)?', command)
        if match:
            return match.group(0).replace('npx -y ', '').strip()
        
        # Fallback for simple npm install commands
        match = re.search(r'npm install -g ([^\s]+)', command)
        if match:
            return match.group(1).strip()

        return None

    def parse_tool(self, row) -> Optional[MCPToolInfo]:
        """è§£æå•ä¸ªå·¥å…·ä¿¡æ¯"""
        try:
            # æ ‡å‡†åŒ–å­—æ®µå
            normalized_row = self.normalize_field_names(dict(row))
            
            name = str(normalized_row.get('name', '')).strip()
            if not name or pd.isna(name):
                return None

            install_command = str(normalized_row.get('install_command', '')).strip()
            package_name = self.extract_package_name(
                install_command, 
                normalized_row.get('run_command'),
                normalized_row.get('deployment_method')
            )

            return MCPToolInfo(
                name=name,
                url=str(normalized_row.get('url', '')).strip(),
                author=str(normalized_row.get('author', '')).strip(),
                github_url=str(normalized_row.get('github_url', '')).strip(),
                description=str(normalized_row.get('description', '')).strip(),
                deployment_method=str(normalized_row.get('deployment_method', '')).strip(),
                package_name=package_name,
                requires_api_key=bool(normalized_row.get('requires_api_key')),
                install_command=install_command,
                run_command=str(normalized_row.get('run_command', '')).strip(),
                final_score=pd.to_numeric(normalized_row.get('final_score'), errors='coerce'),
                sustainability_score=pd.to_numeric(normalized_row.get('sustainability_score'), errors='coerce'),
                popularity_score=pd.to_numeric(normalized_row.get('popularity_score'), errors='coerce'),
                
                # LobeHubè¯„åˆ†ä¿¡æ¯ 
                lobehub_url=str(normalized_row.get('url', '')).strip() if pd.notna(normalized_row.get('url')) else None,
                lobehub_evaluate=str(normalized_row.get('evaluate', '')).strip() if pd.notna(normalized_row.get('evaluate')) else None,
                lobehub_score=pd.to_numeric(normalized_row.get('Unnamed: 5'), errors='coerce') if pd.notna(normalized_row.get('Unnamed: 5')) else None,
                lobehub_star_count=int(pd.to_numeric(normalized_row.get('star_count'), errors='coerce')) if pd.notna(pd.to_numeric(normalized_row.get('star_count'), errors='coerce')) else 0,
                lobehub_fork_count=int(pd.to_numeric(normalized_row.get('fork_count'), errors='coerce')) if pd.notna(pd.to_numeric(normalized_row.get('fork_count'), errors='coerce')) else 0,
            )
            
        except Exception as e:
            console.print(f"[yellow]âš ï¸ è§£æå·¥å…·ä¿¡æ¯å¤±è´¥: {e} for row {row}[/yellow]")
            return None
    
    def get_all_tools(self) -> List[MCPToolInfo]:
        """è·å–æ‰€æœ‰æœ‰æ•ˆçš„MCPå·¥å…·"""
        if self.df is None:
            if not self.load_data():
                return []
        
        tools = []
        for _, row in self.df.iterrows():
            tool = self.parse_tool(row)
            if tool:
                tools.append(tool)
        
        console.print(f"[green]ğŸ“¦ è§£æå‡º {len(tools)} ä¸ªå¯éƒ¨ç½²çš„MCPå·¥å…·[/green]")
        return tools
    
    def find_tool_by_url(self, url: str) -> Optional[MCPToolInfo]:
        """æ ¹æ®URLæŸ¥æ‰¾å·¥å…·"""
        if self.df is None:
            if not self.load_data():
                return None
        
        matches = self.df[self.df['github_url'] == url]
        if not matches.empty:
            return self.parse_tool(matches.iloc[0])
        
        return None
    
    def find_tool_by_package(self, package_name: str) -> Optional[MCPToolInfo]:
        """æ ¹æ®åŒ…åæŸ¥æ‰¾å·¥å…· - æ”¯æŒæ¨¡ç³ŠåŒ¹é…"""
        tools = self.get_all_tools()
        
        # 1. ç²¾ç¡®åŒ¹é…
        for tool in tools:
            if tool.package_name == package_name:
                return tool
        
        # 2. åŒ…å«åŒ¹é… (å»æ‰ç‰ˆæœ¬å·)
        clean_package = package_name.split('@')[0]  # ç§»é™¤ç‰ˆæœ¬å·
        for tool in tools:
            if tool.package_name and clean_package in tool.package_name:
                return tool
        
        # 3. é€šè¿‡install_commandåŒ¹é…
        for tool in tools:
            if tool.install_command and clean_package in tool.install_command:
                return tool
                
        # 4. é€šè¿‡run_commandåŒ¹é…
        for tool in tools:
            if tool.run_command and clean_package in tool.run_command:
                return tool
        
        return None
    
    def get_tools_by_category(self, category: str) -> List[MCPToolInfo]:
        """æ ¹æ®ç±»åˆ«è·å–å·¥å…·"""
        tools = self.get_all_tools()
        return [tool for tool in tools if category.lower() in tool.category.lower()]
    
    def search_tools(self, query: str) -> List[MCPToolInfo]:
        """æœç´¢å·¥å…·"""
        tools = self.get_all_tools()
        query_lower = query.lower()
        
        results = []
        for tool in tools:
            if (query_lower in tool.name.lower() or 
                query_lower in tool.description.lower() or 
                query_lower in tool.author.lower()):
                results.append(tool)
        
        return results

# å…¨å±€è§£æå™¨å®ä¾‹
_parser_instance = None

def get_mcp_parser() -> MCPDataParser:
    """è·å–å…¨å±€MCPè§£æå™¨å®ä¾‹"""
    global _parser_instance
    if _parser_instance is None:
        csv_path = Path(__file__).parent.parent.parent / "data" / "mcp.csv"
        _parser_instance = MCPDataParser(str(csv_path))
    return _parser_instance
